#+HTML_MATHJAX: path:"https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"
#+HTML_HEAD: <script type="text/x-mathjax-config">MathJax.Hub.Config({  TeX: { equationNumbers: { autoNumber: "all" } }});</script>
#+LANGUAGE: zh-hk
#+OPTIONS: H:10 ^:{} html-postamble:nil
** 標量, 向量, 矩陣和張量
+ 標量 :: 標量就是一個單獨的數值. 使用小写斜体表示. 例如 \(\text{令 $\it{n} \in \Bbb{N}$}\), 就是說 n 是一個自然數.
+ 向量 :: 向量是一個數值數組. 通常用小寫的黑體表示. 例如 *x*. 向量的元素斜體加下標表示. 例如 *x* 的第一個元素是 /x_{1}/.
+ 矩陣 :: 矩陣是一個兩維的數值數組. 大寫粗體表示. 例如 *A*. 如果 *A* 是一個 m 行 n列的實數矩陣, 那麼就說 $\mathbf{A} \in \Bbb R^{\mathtt{m\times n}}$.
+ 張量 :: 矩陣的數組在數學上構成張量.

矩陣的一個重要的操作是 *轉置*:
$$
(\mathbf{A}^{\mathtt T} )_{i,j} = A_{i,j}
$$

向量可以看作是只有一列的矩陣. 所以向量的轉置得到的就是只有一行的矩陣. 爲了書寫的方便, 往往使用把一個只有一行的矩陣轉置來表示一個向量

$$
\mathbf x = [x_1,x_2,x_3]^{\mathtt T}
$$
.

一個標量可以看作是只有一個元素的矩陣, 所以, 標量的轉置還是它自己: $a=a^{T}$.

形狀相同的矩陣可以相加, 對應的元素相加就好.\(\mathbf C= \mathbf A + \mathbf B, \text{ 其中, $C_{i,j}=A_{i,j}+B_{i,j}$}\)

還可以在一個矩陣上加上或乘上一個標量, 只要把矩陣上的每個元素都加上或乘上標量就好: \(\mathbf D= a \cdot \mathbf B + c, \text{ 其中, $D_{i,j}=a \cdot B_{i,j} + c$}\).

在深度學習中, 還允許不符合慣例的寫法. 例如把一個矩陣加到一個矢量上得到另外一個矩陣:\( \mathbf C = \mathbf A + \mathbf b, \text{其中, $C_{i,j}=A_{i,j}+b_{j}$}\). 也就是說矢量 *b* 加到了矩陣的每一行上了.

** 矩陣, 向量乘法

矩陣 *A* *矩陣乘* *B*, 得到了第三個矩陣 *C*. *A* 的列數必須和 *B* 的行數一樣. 如果 *A* 是 $m \times n$ 的, *B* 是 $n \times p$, 那麼 *C* 的形狀就是 $m \times p$.
也就是說:
$$
\mathbf C= \mathbf{AB}
$$
被這樣定義:
$$
C_{i,j}=\sum_{k} A_{i,k}B_{k,j}.
$$

對應的矩陣元素的相乘, 叫做 *元素位乘法* 或 *Hadamard 乘法*, 表示位: $A\odot B$.
\begin{align}
\bf{C}=\bf{A}\odot \bf{B}\\
\mathbf{C}_{i,j} =\mathbf{A}_{i,j}\mathbf{B}_{ij}
\end{align}


維度相同的向量 *x* *y* 的點乘, 是矩陣乘法 $\mathbf x^{\mathtt T} \mathbf y$. 所以計算 $\mathbf C= \mathbf{AB}$ 的 $C_{i,j}$ 就可以看作是 *A* 的第 i 行 與 *B* 的第 j 列之間的點乘.

矩陣乘法滿足以下幾個定律:
1. 分配律
  $$
  \mathbf{A(B+C)=AB + AC}
  $$
2. 結合律
  $$
  \mathbf{A(BC)}=\mathbf{(AB)C}
  $$

但是注意, 矩陣乘法不滿足交換律 (commutative), 但是矢量點乘滿足交換律:
$$
\mathbf{x^{\mathtt T}y}=\mathbf{y^{\mathtt T}x}
$$.

矩陣乘的轉置, 滿足以下關係:
$$
(\mathbf{AB})^{\mathtt T} = \mathbf B^{\mathtt T} \mathbf A^{\mathtt T}
$$
所以這樣是因爲, 矢量點乘得到的結果是一個標量, 而標量的轉置等於自身, 所以就有:
$$
\mathbf{x}^{\mathtt T}\mathbf{y}=\left( \mathbf{x}^{\mathtt T} \mathbf{y}\right)^\mathtt T = \mathbf{y}^{\mathtt T}\mathbf{x}
$$

一個矩陣 $\mathbf{A} \in \Bbb{R}^\mathtt{m \times n}$ 乘以一個向量 $\mathbf{x} \in \Bbb{R}^\mathtt{n}$ 得到另外一個向量 $\mathbb{b} \in \Bbb{R}^\mathtt{n}$.
$$
\mathbf{Ax}=\mathbf{b}
$$

這相等於矩陣 *A* 的第 i /行向量/ 與 *x* 相乘得到 *b* 的第 i 個元素.
\begin{array}{ccc}
\mathbf{A}_{1,:}\mathbf{x} & = & b_{1} \\
\mathbf{A}_{2,:}\mathbf{x} & =& b_{2} \\
 &\ldots& \\
\mathbf{A}_{i,:}\mathbf{x} &=& b_{i} 
\end{array}
** 單位矩陣和逆矩陣

*單位矩陣* 是作用到任意矢量上, 都不改變這個矢量的值的矩陣.
一個作用到 n-維 矢量上的單位矩陣標記位 $\mathbf I _n$. 形式化的定義爲, $\mathbf I _n \in \Bbb R^{\mathtt{n \times n}}$, 且:
$$
\forall \mathbf x \in \Bbb R^\mathtt n, \mathbf{I_n x} = \mathbf x
$$

矩陣 *A* 的 *逆* 記爲 $\mathbf{A}^{-1}$. 定義爲:
$$
\mathbf{A}^{-1}\mathbf{A}=\mathbf I _n
$$
有了矩陣的逆, 就可以解矩陣方程:
\begin{align}
\mathbf{Ax}=\mathbf{b} \tag{1.2.1} \\
\mathbf{A}^{\mathtt{-1}}\mathbf{Ax}=\mathbf{A}^{\mathtt{-1}}\mathbf{b}\\
\mathbf{I_{\mathtt{n}}x}=\mathbf{A^{\mathtt{-1}}b}\\
\mathbf{x}= \mathbf{A^{\mathtt {-1}}b}
\end{align}

因此理論上來說, 找矩陣的逆 $\bf{A}^{-1}$ 和 *b* 沒有關係, 找到矩陣的逆之後, 任意的 *b* 都可以應用上面的公式中. 但是在數字計算機中, A 只有有限的精度, 所以實際的編程中, 使用 *b* 的算法, 通常找到的 *x* 的解更加的精確.
** 線性獨立和線性空間
矩陣要存在逆矩陣, 那麼就需要對於任意的方程 1.2.1 必須有唯一的解. 但是對於某些 *b* 來說, 可有無解或者有無數的解. 不可能有多餘一個, 但不是無數個解的 *b* 存在. 因爲, 假設有兩個解 *x*, *y*, 那麼$\mathbf z = \alpha \mathbf x + (1-\alpha) \mathbf y$ 也是一個解, 其中 \alpha 是任意實數.

要分析有多少解, 可以把 $A$ 的列看作是從 *原點* 出發的不同的方向, 他們決定了到達 *b* 有多少中方法. 而 $x_i$ 制定了沿着第 i 列制定的方向上走多遠:
$$
\mathbf{Ax}= \sum_i x_i \mathbf{A}_{:,i}
$$

像這樣的方式叫做線性組合, 也就是說向量 $\mathbf{y}=\mathbf{Ax}$ 是矩陣 *A* 的列向量的線性組合.

*線性組合* 的形式化定義爲: 矢量集合$\{ \mathbf{v}^\mathtt{(1)},\ldots, \mathbf{v}^\mathtt{(n)} \}$, 對每一個矢量 $\mathbf{v}^{(i)}$ 都乘以一個相應的係數, 然後把它們加到一起:
$$
\sum_i c_i \mathbf{v}^{(i)}
$$

矢量集合的 *空間(span)*, 是這個集合中的矢量線性組合組成的點的集合.

所以, $\mathbf{Ax}=\mathbf{b}$ 是否有解, *b* 是否在 *A* 的列向量空間中, 這個特殊的空間, 就叫做 *A* 的 *列空間(column space)* 或 *範圍(range)*.

要求 $\mathbf{Ax}=\mathbf{b},\forall \mathbf{b} \in \Bbb{R}^\mathtt{m}$ 都有唯一的解, 就是要求 *A* 的列空間是 $\Bbb{R}^\mathtt{m}$. 如果其中任意一點不在 *A* 的列空間中, 那麼這點作爲 *b* 的值的話, 方程就沒有解. /要求 *A* 的列空間是 $\Bbb{R}^\mathtt{m}$ 就要求 *A* 至少有 m 列, 也就是說 n \ge m./ 但是列向量的維度 可以小於 m. 例如一個 3 \times 2 的矩陣, 目標 *b* 是 3維的, 但 *x* 是 2維的, 最大限度的改變 *x* 的值, 可以在三位空間中畫出一個平面了, 當且僅當 *b* 在這個平面中的時候, 方程才有解.

但是 n \ge m 只是一個必要條件, 而不是一個充分條件, 因爲列之間可能有冗餘. 例如兩個完全相同的列組成的矩陣, 它實際上和只有一個列組成的矩陣一樣, 只能表示一條線.

這種類型的冗餘叫做 *線性依賴*. 一個矢量集合是 *線性獨立* 的, 如果沒有向量是其他向量的線性組合的話.

m 維向量的集合, 其中彼此線性獨立的向量不會大於 m. 有多餘 m 列的矩陣, (因爲列向量的維度 n 可能大於 m )可能有不只一個 m 個彼此線性獨立的列向量集合.

/要求矩陣有逆, 就是要求公式 1.2.1 最多有一個解. 那麼就是要求 *A* 的列向量最多只有一個集合, 它由 m 個彼此線性獨立的向量構成. 這就要求列向量的維度 $n\le m$./

所以, 這就意味着矩陣必須是 *方陣*. 一個列線性依賴的方陣叫做 *奇異陣*. 

*一個方陣, 如果列向量線性獨立, 就有逆.*
** Norms
計算一個向量的大小的函數, 叫做 *範數 (norm)*. $L^p$ 範數的定義爲:

$$
\| \mathbf x \|_p =\left( \sum_i |x_i|^p \right)^{\frac{1}{p}}, \text{for } p \in \Bbb R, p \ge 1
$$

$L^p$ 讀若, p 階範數.

範數, 包括 L^{p} 範數, 是把一個矢量映射乘一個非負值的函數.

可以作爲範數的函數 f , 需要滿足以下幾個條件:
+ $f(\mathbf x)= 0 \Rightarrow \mathbf x = \mathbf 0$.
+ $f(\mathbf x + \mathbf y) \le f(\mathbf x) + f(\mathbf y)$ (三角形不等式)
+ $forall \alpha \in \Bbb R,f(\alpha \mathbf x) = | a | f(\mathbf x)$

L^{2} 範數是最常見的範數, 也叫做 *歐幾里德範數*.

在機器學習中, 通常使用 L^{2} 的平方, 因爲 L^{2} 的平方比 L^{2} 的計算更加容易. 例如 L^{2} 平凡對 *x* 的元素的導數, 只和對應的元素相關, 而 L^2 對 *x* 的元素的導數, 卻和整個的矢量相關. 但是在接近原點的地方, L^{2} 的平方, 增長的非常慢.

L^{1} 定義如下:
$$
\| \mathbf x \| _ 1 = \sum_ i | x_i |,
$$
當 *x* 增加 \epsilon, L^{1} 範數也增加 \epsilon.

有時把矢量的非零元素的個數叫做 "L^{0} 範數". 實際上, 非零元素的個數不是範數, 因爲不符合範數的第三個條件.

L^{\infty} 叫做最大範數. 最大範數非常的簡單, 就是矢量的元素的絕對值最大的那個絕對值:
$$
\| \mathbf x \| _\infty = \max_ i | x_i | .
$$

*Frobenius norms*, 可以用來表示一個矩陣的大小:
$$
\| A \|_ F = \sqrt{\sum_{i,j} A^2_{i,j} }
$$
** 特殊的矩陣
*對角矩陣* 是非零元素只存在於主對角線上的矩陣. 如果滿足 $\mathbf D _{i,j} = 0, \forall i \ne j$, 就說矩陣 *D* 是對角矩陣. 使用 $diag( \mathbf v )$ 表示對角方陣, 其中的對角元素由矢量 $\mathbf v$ 給出.
+ $diag(\mathbf v)\mathbf x = \mathbf v \odot \mathbf x$
+ $diag( \mathbf v )^{-1} =diag([1/v_1, \ldots, 1/v_n]^T)$

不是所有的對角矩陣都必須是方陣. 對於非方陣對角矩陣 *D*, $\mathbf{Dx}$ 會縮放 *x* 的每個元素; 如果 *D* 高大於寬的話, 就由一連串的零填充, 如果 *D* 的寬大於高的話, 就丟棄這個矢量的最後的一些元素.

如果滿足一些條件, 就說這個矩陣是 *對稱* 的:
$$
\mathbf{A}=\mathbf{A}^\mathtt{T}
$$

*單位矢量* 是一個有 *一個單位的範數* 的矢量:
$$
\|\mathbf{x}\|_2 = 1
$$
*正交矩陣* 是一個方陣, 它的列相互之間正交, 行相互之間也正交:
$$
\mathbf{A}^\mathtt{T}\mathbf{A} = \mathbf{AA}^\mathtt{T} = \mathbf{I}
$$
也就是說, 對於正交矩陣滿足:
$$
\mathbf{A}^{-1}=\mathbf{A}^{T}
$$
** 本徵分解
把一個矩陣, 分解爲本徵矢量和本徵值的集合, 這樣的分解叫做 *本徵分解*.

一個方陣 *A* 的 *本徵矢量*, 是非零的矢量 *v*, 滿足以下關係:

$$
\mathbf{Av} = \lambda \mathbf{v}
$$
標量 \lambda 叫做對應本徵矢量的 *本徵值*.

如果 *v* 是 *A* 的本徵矢量, 那麼任意的放大這個矢量 $s\mathbf{v} \text{ for }s  \in \Bbb R, s \ne 0$, 依然是本徵矢量, 而且對應的本徵值一樣, 所以, 通常找單位本徵矢量.

*A* 的線性獨立的本質矢量 $\{\mathbf{v}^{(1)}, \ldots, \mathbf{v}^{(n)}\}$ 對應的本徵值是 $\{\lambda_1,\ldots,\lambda_n\}$, 那麼由每個本徵矢量作爲一列, 組成矩陣 *V*: $\mathbf{V}=[\mathbf{v}^{(1)},\ldots,\mathbf{v}^{(n)}]$, 把對應的本徵值排列成爲一個矢量: $\mathbf{\lambda}=[\lambda_1,\ldots,\lambda_n]^\mathtt{T}$. 那麼 *A* 的本徵分解爲:
$$
\mathbf{A}=\mathbf{V} diag(\mathbf{\lambda})\mathbf{V}^{-1}
$$

通過本徵矢量來構造矩陣, 可以讓我們按照自己期望的方式來撐起一個空間. 但是更多的時候, 我們是希望把一個矩陣 *分解* 爲他的本徵矢量. 這樣做可以讓我分析矩陣的某些特性.

任意的實對稱矩陣, 都可以使用實數的本徵矢量和本徵值分解:
$$
\mathbf A =\mathbf{Q\Lambda Q}^\mathtt T
$$
其中, *Q* 是由 *A* 的本徵矢量組成的正交矩陣, *\Lambda{}* 是對角矩陣.本徵值 \Lambda_{i,i} 對應的本徵矢量爲 *Q* 的第 i 列, $\mathbf{Q}_{:,i}. 因爲 *Q* 是一個正交矩陣, 所以我們可以把 *A* 看作是在 $\mathbf{v}^{(i)}$ 的方向上放大 \lambda_{i}$ 倍後形成的空間.

一個矩陣是奇異的, 當且僅當由本徵矢量是0.

實對稱矩陣的本徵分解, 在要求 $\|\mathbf{x}\|_2= 1$ 時, 可以用來優化形如 $f(\mathbf{x})=\mathbf{x}^{\mathbf T}\mathbf{Ax}$. 這樣 *x* 可以看作是矩陣 *A* 的本徵矢量, 函數 f 返回的是本徵矢量對應的本徵值. 這樣在滿足約束條件下, 最大值是本徵值中的最大值, 最小值是本徵值中的最小值.

** 奇異矩陣分解
*奇异值分解(singular value decomposition, SVD)* 是另一种把矩阵分解为 *奇异矢量* 和 *奇异值* 的方法.

*每个实矩阵都由一个奇异值分解*, 但是并不一定由本征分解.

奇异值分解, 把矩阵 *A* 分解为三个矩阵的乘积:
$$
\mathbf{A}=\mathbf{UDV}^\mathtt{T}
$$
如果 *A* 是一个 $m\times n$, *U* 被定义为 $m\times m$, *D* 是一个 $m \times n$, 而 *V* 是一个 $n \times n$ 矩阵.
举证 *U* 和 *V* 都是正交矩阵. 矩阵 *D* 是对角矩阵, 不必是方陣.

*D* 叫做矩陣 *A* 的奇異值. *U* 的列叫做 *左奇異矢量*; 相應的, *V* 的列叫做右奇異矢量.
*A* 的左奇異矢量是 $\mathbf{AA}^\mathtt{T}$ 的特徵矢量. *A* 的右奇異矢量是 $\mathbf{A}^\mathtt{T}\mathbf{A}$ 的本徵矢量.

** Moore-Penrose 贗逆矩陣
非方陣沒有逆操作的定義. 如果我們想要計算 *A* 的左逆, 以便解線性方程:
$$
\mathbf{Ax}=\mathbf{y}
$$
左乘 *B* 就等得到了:
$$
\mathbf x = \mathbf{By}
$$
如果 *A* 的高大於他的寬, 方程可能無解. 如果寬大於高, 那麼可能由多個解.

*A* 的贗逆是如下定義的矩陣:
$$
\mathbf{A}^{+}=\lim_{\alpha \to 0} (\mathbf{A}^\mathtt{T}\mathbf{A}+\alpha\mathbf{I})^{-1}\mathbf{A}^\mathtt{T}
$$
實踐中, 很少使用這個定義, 而是通過下面的方法:
$$
\mathbf{A}^+ = \mathbf{VD}^+\mathbf{U}^T
$$
其中, *U*, *D*, *V* 是 *A* 的奇異分解, 對角矩陣 *D* 的贗逆 *D^{+}* 通過對非零元素取倒數, 然後轉置得到.

如果 *A* 的列多於行, 贗逆給出多個解中的一個. $\mathbf{x} = \mathbf{A}^+ \mathbf y$ 是所有解中, 歐幾里德範數最新的解.

如果 *A* 的行多於列, 贗逆給出的 *x* 使得 $\| \mathbf{Ax} - \mathbf{y} \|_2$ 最小.
** 跡操作符
跡操作符給出了矩陣的所有所有的對角元素的和:
$$
Tr(\mathbf{A}) = \sum_i \mathbf{A}_{i,i}
$$

\begin{array}{l}
Tr(\mathbf{A}) = Tr(\mathbf{A}^{T})\\
Tr(\mathbf{ABC})=Tr(\mathbf{CAB})=Tr(\mathbf{BCA})\\
Tr(\prod_{i=1}^{n}\mathbf{F}^{(i)}) = Tr(\mathbf F^{(n)}\prod_{i=1}^{n-1} F^{(i)}\notag
\end{array}

** 行列式的值
一個方陣的行列式的值, 記作 $det(\mathbf A)$, 是一個把一個矩陣映射爲一個實標量. 行列式的值是矩陣的本徵值的乘積. 

