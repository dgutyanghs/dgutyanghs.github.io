* 一个特定(Ad-Hoc) 领域
深度学习还是一个非常新的领域. 人工智能模型已经被研究了十多年了, 但是过去的的成绩和现在的结果之间的联系非常的纤细.

一个新的领域, 往往是从一个非常特殊的方式开始的. 然后, 这个领域成熟之后, 对这个领域的理解与最开始的参与者的理解之间差距非常大.

深度学习看起来就非常想就处于这样的特定状态.

目前, 深度学习被一些极其成功的工具掌控. 这些工具看起来并没有结实的基础; 有时候, 我们会被任意的细节上的规则的改变所绊倒. 作为一个领域, 我们还没有同意的洞察或共享的理解.

* 未来 30 年的深度学习
目前对深度学习有 3 种相互竞争的叙述. 
+ 神经学叙述, 也就是模拟生物. 
+ 表示叙述, 核心就是转化数据以及汇集假设.
+ 概率叙述, 把神经网络解释为发现潜在变量的方法.

当然这些叙述不是互斥的. 但是他们在看待深度学习上表现的的确的非常的不同.

以表示叙述来看深度学习的论文中给出的最新的答案: 深度学习研究优化与函数编程之间的关系.

以这种视角, 深度学习的表达式叙述与函数编程中的类型理论联系起来了. 看起来深度学习就像我们已经非常熟悉的两个领域的交汇点.

* 优化与函数的比较
深度学习的独特的特性是它研究很深的神经网络-- 有很多层的神经网络. 通过多层网络, 这些模型持续的转化数据, 把它封装成容易解决给定任务的形式.

每一层是一个函数, 作用在上一层的输出上. 整体来看, 网络就是一个复合函数链. 这个复合函数链被优化来完成一个任务.

在深度学习中每个模型都涉及到对复合函数的优化.
* 表示是类型
在每一层, 神经网络转化数据, 把数据建立模型形成一个可以让他们的任务变的简单的形式. 我们称这些换行后的数据为 "表示".

表示对应的是类型.

类型在计算机科学中, 是在 n 位中谦虚一些数据. 类似的, 表示在深度学习中是, 在 n 维中嵌入一个数据量.

就像只有两个函数的类型一致, 它们才能复合一样, 只有两层的表示一致的时候, 这两层才能复合在一起. 在训练的过程中, 相邻的层协商它们沟通的表示; 网络的效果依赖于这个网络期待的表示中的数据.

* 深度学习 & 函数编程
现在神经网络背后的关键洞察是: 一个神经元的拷贝可以在神经网络中使用多次这种思想.

在编程中, 函数的抽象是本质. 不是把一些代码写十次, 百次甚至前次, 而是写一次, 而需要调用几次就调用几次. 这样做不仅仅减少了我们需要写和维护的代码数量, 加速的开发速度, 而且也减少了引入错误的风险, 使我们引入的错误很容易被找到.

在不同的地方多次使用一个神经元的拷贝, 是 神经元网络等价于使用函数的地方. 因为这样学的更少, 便可以使得模型学习的更快, 且学习更好的模型.


